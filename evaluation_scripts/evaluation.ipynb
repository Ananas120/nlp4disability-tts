{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation des différents modèles pour l'article NLP4Disability sur les modèles de Text-To-Speech (TTS)\n",
    "\n",
    "**Auteur : Langlois Quentin, promoteur : Jodogne Sébastien**\n",
    "\n",
    "**Ni ce code ni aucun audio ne peut être partagé au moins jusqu'à la publication de l'article, merci de votre compréhension ! :)**\n",
    "\n",
    "Dans le cadre d'un article pour le workshop [NLP4Disability](http://www.wikicfp.com/cfp/servlet/event.showcfp?eventid=171220), j'ai entrainé plusieurs modèles de clonage de voix avec des nombres plus ou moins élevés d'exemples d'entrainement. Le but est de les comparer selon les metriques classiques MOS (*naturalness*) et CMOS (*qualité relative*), ainsi qu'une nouvelle métrique évaluant *l'agréabilité* de la voix dans un texte plus long.\n",
    "\n",
    "**Toutes ces métriques sont subjectives par nature, c'est pour ça que je demande à un maximum de personnes de faire cette évaluation, donc fiez vous à votre appréciation personnelle !**\n",
    "Pour lancer l'évaluation, vous devez juste exécuter les différentes cellules dans l'ordre et entrer les valeurs demandées ! ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exécutez cette cellule pour faire les différents imports de librairies\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "def is_valid_float(v):\n",
    "    try:\n",
    "        float(v)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def load_json(filename, default = {}, ** kwargs):\n",
    "    \"\"\" Safely load data from a json file \"\"\"\n",
    "    if not os.path.exists(filename): return default\n",
    "    with open(filename, 'r', encoding = 'utf-8') as file:\n",
    "        result = file.read()\n",
    "    return json.loads(result)\n",
    "\n",
    "def dump_json(filename, data, ** kwargs):\n",
    "    \"\"\" Safely save data to a json file \"\"\"\n",
    "    data = json.dumps(data, ** kwargs)\n",
    "    with open(filename, 'w', encoding = 'utf-8') as file:\n",
    "        file.write(data)\n",
    "\n",
    "def display_audio(filename, play = True):\n",
    "    \"\"\" Displays an audio file into the notebook \"\"\"\n",
    "    display(Audio(filename, autoplay = play))\n",
    "\n",
    "def ask_result(msg, value_checker, value_message):\n",
    "    \"\"\" Shows `msg` until the user enters a value inside `values` \"\"\"\n",
    "    res = input(msg)\n",
    "    while not value_checker(res):\n",
    "        res = input(\"{} n'est pas une valeure valide ! {}\\n{}\".format(res, value_message, msg))\n",
    "    \n",
    "    return res\n",
    "\n",
    "# Transcript of the first 74 seconds splitted into 10 parts\n",
    "sentences = [\n",
    "    \"Vingt mille lieues sous les mers, tôme un, première partie. Chapitre un, un écueil fuyant.\",\n",
    "    \"L'année 1866, fut marquée par un événement bizarre, un phénomène inexpliqué et inexplicable que personne n'a sans doute oublié.\",\n",
    "    \"Sans parler des rumeurs qui agitaient les populations des ports, et surexcitaient l'esprit public à l'intérieur des continents, les gens de mers furent particulièrement émus.\",\n",
    "    \"Les négociants, armateurs, capitaines de navires, skippers et master de l'Europe et de l'Amérique, officiers des marines militaires de tous pays et,\",\n",
    "    \"après eux, les gouvernements des divers états des deux continents, se préoccupèrent de ce fait au plus haut point\",\n",
    "    \"En effet, depuis quelques temps, plusieurs navires s'étaient rencontrés sur mer avec une chose énorme.\",\n",
    "    \"Un objet long, fusiforme, parfois phosphorescent, infiniment plus vaste et plus rapide qu'une baleine.\",\n",
    "    \"Les faits relatifs à cette apparition, consignés aux divers livres de bord, s'accordaient assez exactements sur la structure de l'objet ou de l'être en question.\",\n",
    "    \"La vitesse incalculable de ses mouvements, la puissance surprenante de sa locomotion, la vie particulière dont il semblait doué.\",\n",
    "    \"Si c'était un cétacé, il surpaçait en volume tous ceux que la science avait classés jusqu'à l'or.\",\n",
    "    \"Ni cuvier, ni l'acépède, ni monsieur Duméryl, ni monsieur de quatre fages, n'eussent admis l'existence d'un tel monstre.\",\n",
    "    \"A moins de l'avoir vu, ce qui s'appelle vu, de leurs propres yeux de savants.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Long-term Mean Opinion Score (LMOS)` : qualité dans un contexte d'audio-book\n",
    "\n",
    "Cette partie vise à évaluer si un extrait audio provenant d'un livre (ici *20 000 lieues sous les mers*) est agréable à écouter ou non. Cela vise donc à évaluer la qualité générale de la voix (rythme, fluidité, intonation) ainsi que de l'audio en général (bruit, ...) dans un contexte d'audio-book. \n",
    "\n",
    "1) La 1ère valeur demandée est un score d'appréciation de 0 à 5 avec un pas de 0.5 (0, 0.5, 1, ..., 4.5, 5) :\n",
    "    - 0 : très mal lu et pas agréable à écouter\n",
    "    - 3 : bien lu mais pas très agréable à long terme\n",
    "    - 4+ : malgré quelques erreurs de prononciation / rythme, je pourrais écouter la suite du livre avec cette voix.\n",
    "    - 5 : prononciation parfaite et agréable à écouter.\n",
    "\n",
    "2) La 2ème évaluation vise à comparer les différents modèles dans l'ordre de préférence. La question est de savoir \"sur base de quel extrait vous aimeriez continuer à écouter le livre\".\n",
    "\n",
    "**Cette évaluation ne vise pas à déterminer si la personne est humaine ou non. Un humain qui lirait mal ou dont vous n'aimeriez pas la voix pourrait avoir un score inférieur à 4.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_lmos(filename = 'result.json', directory = 'audios', metric_name = 'lmos', possible_values = np.linspace(0, 5, 11)):\n",
    "    filename  = os.path.join(directory, filename)\n",
    "    infos     = load_json(filename)\n",
    "    directory = os.path.join(directory, metric_name)\n",
    "    \n",
    "    if (len(infos.get(metric_name, {}).get('order', [])) == len(os.listdir(directory)) and\n",
    "        len(infos.get(metric_name, {}).get('score', [])) == len(os.listdir(directory))):\n",
    "        print(\"L'évaluation pour {} a déjà été faite !\".format(metric_name))\n",
    "        return infos[metric_name]\n",
    "    \n",
    "    print(\"Texte :\\n{}\".format('\\n'.join(sentences)))\n",
    "    \n",
    "    infos.setdefault(metric_name, {'order' : [], 'score' : {}})\n",
    "    files = glob.glob(os.path.join(directory, '*.mp3'))\n",
    "    for i, file in enumerate(files):\n",
    "        if file in infos[metric_name]['score']: continue\n",
    "        \n",
    "        print('Audio {} / {}'.format(i + 1, len(files)))\n",
    "        display_audio(file)\n",
    "        \n",
    "        res = float(ask_result(\n",
    "            'Entrez votre évaluation sur l\\'aspect agréable de l\\'extrait :',\n",
    "            lambda v: is_valid_float(v) and float(v) in possible_values,\n",
    "            \"Les valeurs possibles sont {}\".format(possible_values)\n",
    "        ))\n",
    "        \n",
    "        infos[metric_name]['score'][file] = res\n",
    "        dump_json(filename, infos, indent = 4)\n",
    "        print('\\n')\n",
    "    \n",
    "    # Displays the different audios with their ID (index)\n",
    "    for i, file in enumerate(sorted(glob.glob(os.path.join(directory, '*.mp3')))):\n",
    "        print('Audio {}'.format(i))\n",
    "        display_audio(file, play = False)\n",
    "    \n",
    "    n, order = len(infos[metric_name]['score']), []\n",
    "    for i in range(n):\n",
    "        order.append(int(ask_result(\n",
    "            'Quel extrait est choix n°{} (1er = préféré) :'.format(i + 1),\n",
    "            lambda v: is_valid_float(v) and int(v) in list(range(n)) and int(v) not in order,\n",
    "            \"Les valeurs possibles sont {}\".format([i for i in range(n) if i not in order])\n",
    "        )))\n",
    "    \n",
    "    infos[metric_name]['order'] = order\n",
    "    dump_json(filename, infos, indent = 4)\n",
    "    \n",
    "    return infos\n",
    "\n",
    "print(\"Fini ! Merci pour cette évaluation !\\n Résultat : {}\".format(json.dumps(evaluate_lmos(), indent = 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Comparative) Mean Opinion Score (MOS / CMOS) : comparaison entre l'original et la voix de synthèse\n",
    "\n",
    "- `Mean Opinion Score (MOS)` : vise à évaluer la qualité générale de différents audios sur une échelle de 0 à 5 avec un pas de 0.5 (0, 0.5, 1, ..., 4.5, 5). Pour chaque modèle, il y aura une série de phrases lues par le modèle ou la personne. Le but est de noter la qualité de l'extrait et **non de déterminer le(s)quel(s) est / sont faux.**\n",
    "\n",
    "- `Comparative Mean Opinion Score (CMOS)` : ce metric vise à donner un score entre -3 (l'extrait est bien + mauvais) à 3 (l'extrait est de bien meilleure qualité), avec un pas de 0.5, par rapport à une référence. Pour chaque voix, vous aurez une référence + une série d'extraits à comparer à la référence. \n",
    "\n",
    "Pour vous éviter de devoir écouter 2x tous les audios, je demanderai les 2 metrics l'un à la suite de l'autre. Le 1er audio présenté (pour une certaine phrase) sera toujours la référence (et aura donc un CMOS de 0 par défaut). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mos(voice, filename = 'result.json', directory = 'audios', mos_values = np.linspace(0, 5, 11), cmos_values = np.linspace(-3, 3, 13)):\n",
    "    \"\"\"\n",
    "        Evaluates the different audios for the `MOS` metric\n",
    "        Creates a dict of the following structure :\n",
    "            'mos' : {\n",
    "                voice : {\n",
    "                    'score' : {\n",
    "                        filename : mos_score\n",
    "                        ...\n",
    "                    },\n",
    "                    'cmos'   : {\n",
    "                        filename : cmos_score\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "    \"\"\"\n",
    "    filename  = os.path.join(directory, filename)\n",
    "    infos     = load_json(filename)\n",
    "    directory = os.path.join(directory, 'mos', voice)\n",
    "    if len(infos.get('mos', {}).get(voice, {}).get('score', [])) == len(os.listdir(directory)):\n",
    "        print(\"L'évaluation pour {} a déjà été faite !\".format(voice))\n",
    "        return infos['mos'][voice]\n",
    "    \n",
    "    infos.setdefault('mos', {})\n",
    "    infos['mos'].setdefault(voice, {'score' : {}, 'cmos' : {}})\n",
    "    \n",
    "    n_sent  = len([f for f in os.listdir(directory) if '_0.mp3' in f])\n",
    "    n_model = len([f for f in os.listdir(directory) if 'audio_0' in f])\n",
    "    for i in range(n_sent):\n",
    "        ref_filename = os.path.join(directory, 'audio_{}_1.mp3'.format(i))\n",
    "        if ref_filename in infos['mos'][voice]['score']: continue\n",
    "        \n",
    "        print('Audio de référence (phrase {} / {}) :'.format(i + 1, n_sent))\n",
    "        display_audio(ref_filename)\n",
    "        \n",
    "        infos['mos'][voice]['score'][ref_filename] = float(ask_result(\n",
    "            'Entrez votre score pour cet audio :',\n",
    "            lambda v: is_valid_float(v) and float(v) in mos_values,\n",
    "            \"Les valeurs possibles sont {}\".format(mos_values)\n",
    "        ))\n",
    "        \n",
    "        for j in range(n_model):\n",
    "            if j == 1: continue\n",
    "\n",
    "            filename_ij = os.path.join(directory, 'audio_{}_{}.mp3'.format(i, j))\n",
    "            print('Audio à comparer :')\n",
    "            display_audio(filename_ij)\n",
    "\n",
    "            infos['mos'][voice]['score'][filename_ij] = float(ask_result(\n",
    "                '1) Entrez votre score pour cet audio :',\n",
    "                lambda v: is_valid_float(v) and float(v) in mos_values,\n",
    "                \"Les valeurs possibles sont {}\".format(mos_values)\n",
    "            ))\n",
    "            \n",
    "            infos['mos'][voice]['cmos'][filename_ij] = float(ask_result(\n",
    "                '2) Entrez votre score en comparaison avec la référence :',\n",
    "                lambda v: is_valid_float(v) and float(v) in cmos_values,\n",
    "                \"Les valeurs possibles sont {}\".format(cmos_values)\n",
    "            ))\n",
    "\n",
    "        dump_json(filename, infos, indent = 4)\n",
    "        \n",
    "        print('\\n')\n",
    "    \n",
    "    return infos\n",
    "\n",
    "voices = os.listdir(os.path.join('audios', 'mos'))\n",
    "for i, voice in enumerate(voices):\n",
    "    print(\"Début de l'évaluation pour la voix {} ({} / {})...\".format(voice, i + 1, len(voices)))\n",
    "    print(\"Résultat : {}\".format(json.dumps(evaluate_mos(voice), indent = 4)))\n",
    "\n",
    "print(\"Fini ! Merci pour cette évaluation, n'oubliez pas de m'envoyer le fichier result.json dans le répertoire audios/ !\")\n",
    "display_audio(os.path.join('audios', 'fin.mp3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Création des différents audios\n",
    "\n",
    "**Ces cellules ne doivent pas être exécutées et ne doivent pas être explorées avant l'évaluation !** Elles sont là à titre informatif pour que vous puissiez voir comment les différents audios ont été générés.\n",
    "\n",
    "Le code de génération ainsi que plusieurs des modèles proviennent de [ce github](https://github.com/yui-mhcp/text_to_speech)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.audio import read_audio, write_audio, display_audio\n",
    "# Extract the 74 first seconds of Jules Verne, 20000 lieues sous les mers\n",
    "rate, audio = read_audio('../__test_datas/verne-2000-part1.mp3')\n",
    "write_audio(filename = '../__test_datas/verne-2000-part1_sample.mp3', audio = audio[: 120 * rate], rate = rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "# Small help to pre-transcribe the audio\n",
    "# `whisper` is available at `https://github.com/openai/whisper`\n",
    "whisper.transcribe(whisper.load_model('base'), '../__test_datas/verne-2000-part1_sample.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays it for a better transcription\n",
    "_ = display_audio(audio[70 * rate : 120 * rate], rate = rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from utils.audio import display_audio\n",
    "\n",
    "# Transcript of the first 74 seconds splitted into 10 parts\n",
    "sentences = [\n",
    "    \"Vingt mille lieues sous les mers, tôme un, première partie. Chapitre un, un écueil fuyant.\",\n",
    "    \"L'année 1866, fut marquée par un événement bizarre, un phénomène inexpliqué et inexplicable que personne n'a sans doute oublié.\",\n",
    "    \"Sans parler des rumeurs qui agitaient les populations des ports, et surexcitaient l'esprit public à l'intérieur des continents, les gens de mers furent particulièrement émus.\",\n",
    "    \"Les négociants, armateurs, capitaines de navires, skippers et master de l'Europe et de l'Amérique, officiers des marines militaires de tous pays et,\",\n",
    "    \"après eux, les gouvernements des divers états des deux continents, se préoccupèrent de ce fait au plus haut point\",\n",
    "    \"En effet, depuis quelques temps, plusieurs navires s'étaient rencontrés sur mer avec une chose énorme.\",\n",
    "    \"Un objet long, fusiforme, parfois phosphorescent, infiniment plus vaste et plus rapide qu'une baleine.\",\n",
    "    \"Les faits relatifs à cette apparition, consignés aux divers livres de bord, s'accordaient assez exactements sur la structure de l'objet ou de l'être en question.\",\n",
    "    \"La vitesse incalculable de ses mouvements, la puissance surprenante de sa locomotion, la vie particulière dont il semblait doué.\",\n",
    "    \"Si c'était un cétacé, il surpaçait en volume tous ceux que la science avait classés jusqu'à l'or.\",\n",
    "    \"Ni cuvier, ni l'acépède, ni monsieur Duméryl, ni monsieur de quatre fages, n'eussent admis l'existence d'un tel monstre.\",\n",
    "    \"A moins de l'avoir vu, ce qui s'appelle vu, de leurs propres yeux de savants.\"\n",
    "]\n",
    "# models to evaluate\n",
    "models = []\n",
    "\n",
    "def create_lmos_samples(model_name, mode = 0, directory = 'audios', overwrite = False, debug = False):\n",
    "    from models import get_pretrained, is_model_name\n",
    "    from utils import select_embedding\n",
    "    from utils.audio import write_audio, load_audio\n",
    "    \n",
    "    if not is_model_name(model_name): return None\n",
    "    \n",
    "    directory = os.path.join(directory, model_name, 'lmos')\n",
    "    if os.path.exists(directory) and len(os.listdir(directory)) >= len(sentences) + 1:\n",
    "        if not overwrite: return directory\n",
    "        shutil.rmtree(directory)\n",
    "    \n",
    "    os.makedirs(directory, exist_ok = True)\n",
    "\n",
    "    model    = get_pretrained(model_name)\n",
    "    waveglow = get_pretrained('WaveGlow')\n",
    "    model.load_embeddings()\n",
    "    \n",
    "    silence = np.zeros((int(0.15 * model.audio_rate), ))\n",
    "    \n",
    "    audios = []\n",
    "    for i, sent in enumerate(sentences):\n",
    "        audio_file = os.path.join(directory, 'audio_{}.mp3'.format(i))\n",
    "        if os.path.exists(audio_file):\n",
    "            audio = load_audio(audio_file, model.audio_rate)\n",
    "        else:\n",
    "            audio = waveglow.infer(model.infer(sent, select_embedding(model.embeddings, mode = mode))[1])[0]\n",
    "\n",
    "            write_audio(\n",
    "                filename = audio_file, audio = audio, rate = model.audio_rate\n",
    "            )\n",
    "        if debug: display_audio(audio_file, play = False)\n",
    "        audios.extend([audio, silence])\n",
    "    \n",
    "    write_audio(\n",
    "        filename = os.path.join(directory, 'full_audio.mp3'),\n",
    "        audio    = np.concatenate(audios[:-1]),\n",
    "        rate     = model.audio_rate\n",
    "    )\n",
    "    \n",
    "    return directory\n",
    "\n",
    "for model in models:\n",
    "    print('Generating for {}...'.format(model))\n",
    "    directory = create_lmos_samples(model, overwrite = False, mode = 0, debug = False)\n",
    "    if directory: display_audio(os.path.join(directory, 'full_audio.mp3'))\n",
    "    \n",
    "    create_cmos_samples(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Comparative) Mean Opinion Score (CMOS / MOS) sample pairs creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_dataset, get_dataset_dir\n",
    "# models to evaluate\n",
    "voices = {\n",
    "    'siwis'  : {'models' : (), 'dataset' : 'siwis'},\n",
    "    'kaggle' : {'models' : (), 'dataset' : 'kaggle_tts'}\n",
    "}\n",
    "\n",
    "def create_mos_samples(voice, infos, n = 25, mode = 0, directory = 'audios', overwrite = False, debug = False):\n",
    "    \"\"\"\n",
    "        Creates the MOS samples based on\n",
    "        \n",
    "        Creates a directory with the following structure :\n",
    "            {directory}/\n",
    "                mos/\n",
    "                    {voice}/\n",
    "                        audio_{i}_{j}.mp3\n",
    "            \n",
    "            - i represents the id of the sentence\n",
    "            - j represents the id of the speaker (either human or synthesized)\n",
    "    \"\"\"\n",
    "    from models import get_pretrained\n",
    "    from utils import select_embedding\n",
    "    from utils.audio import write_audio, load_audio, load_mel\n",
    "    \n",
    "    directory = os.path.join(directory, 'mos', voice)\n",
    "    if os.path.exists(directory) and len(os.listdir(directory)) == n * (len(infos['models']) + 2):\n",
    "        if not overwrite: return directory\n",
    "        shutil.rmtree(directory)\n",
    "    \n",
    "    os.makedirs(directory, exist_ok = True)\n",
    "\n",
    "    if isinstance(infos['dataset'], str):\n",
    "        dataset = get_dataset(infos['dataset'])\n",
    "    else:\n",
    "        dataset = get_dataset(** infos['dataset'])\n",
    "    if isinstance(dataset, dict): dataset = dataset['valid']\n",
    "    \n",
    "    samples = dataset.sample(n, random_state = 42)\n",
    "    \n",
    "    # Load models\n",
    "    for model in infos['models']: get_pretrained(model)\n",
    "    waveglow = get_pretrained('WaveGlow')\n",
    "    \n",
    "    mel_fn   = get_pretrained(infos['models'][0]).mel_fn\n",
    "    \n",
    "    # creates the original audio\n",
    "    for i, filename in enumerate(samples['filename'].values):\n",
    "        if not os.path.exists(os.path.join(directory, 'audio_{}_1.mp3'.format(i))):\n",
    "            # Copy the original audio (i.e. read by the human), resampled to 22050Hz\n",
    "            audio = load_audio(filename, 22050)\n",
    "            write_audio(filename = os.path.join(directory, 'audio_{}_0.mp3'.format(i)), audio = audio, rate = 22050)\n",
    "            # Creates a synthesized audio based on the ground truth (to assess the vocoder's quality)\n",
    "            inverted_audio = waveglow.infer(load_mel(filename, mel_fn))[0]\n",
    "            write_audio(filename = os.path.join(directory, 'audio_{}_1.mp3'.format(i)), audio = inverted_audio, rate = 22050)\n",
    "\n",
    "    for j, model_name in enumerate(infos['models']):\n",
    "        model = get_pretrained(model_name)\n",
    "        model.load_embeddings()\n",
    "        \n",
    "        for i, text in enumerate(samples['text'].values):\n",
    "            audio_file_ij = os.path.join(directory, 'audio_{}_{}.mp3'.format(i, j + 2))\n",
    "            if not os.path.exists(audio_file_ij):\n",
    "                synth_audio = waveglow.infer(model.infer(text, select_embedding(model.embeddings, mode = mode))[1])[0]\n",
    "                write_audio(filename = audio_file_ij, audio = synth_audio, rate = 22050)\n",
    "    \n",
    "    return directory\n",
    "\n",
    "for voice, infos in voices.items():\n",
    "    print('Generating for voice {}...'.format(voice))\n",
    "    create_mos_samples(voice, infos, n = 25, overwrite = False, mode = 0, debug = False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
